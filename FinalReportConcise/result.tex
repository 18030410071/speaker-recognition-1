\section{Performance}
\label{sec:result}
We have tested our approaches under various parameters, based on a corpus provided by teacher Xu.
For detailed description of the corpus, please see former report.

All the tests in this section have been conducted serval times
(depending on computation cost, vary from 10 to 30)
with random selected training and testing speakers.
The average over these tests are considered as confidential result.

\subsection{Efficiency Test of our GMM}
We have extensively examined the efficiency of our implementation of GMM
compared to scikit-learn version. Test is conducted using real MFCC data with
13 dimensions, 20ms frame length. We consider the scenario when training a UBM with 256 mixtures.
We examine the time used for ten iteration.  For comparable results, we diabled
the K-means initialization process of both scikit-learn GMM implementation and
ours. Time used for ten iterations under different data size and concurrency
is recorded.

\begin{figure}[!ht]
	\begin{minipage}{0.48\linewidth}
		\centering
		\includegraphics[width=\linewidth]{img/time-comp.pdf}
		\caption{Comparison on efficiency\label{fig:gmm_efficiency}}
	\end{minipage}
	\hfill
	\begin{minipage}{0.48\linewidth}
		\centering
		\includegraphics[width=\linewidth]{img/time-comp-small.pdf}
		\caption{Comparison on efficiency when number of MFCC features is small\label{fig:gmm_efficiency_small}}
	\end{minipage}
\end{figure}

From \figref{gmm_efficiency}, we can immediately infer that our method
is much-much more efficient than the widely used version of GMM provided
by scikit-learn when the data size grows sufficiently large.

We shall analyze in two aspect:
\begin{itemize}
    \item No concurrency
        \begin{itemize}
            \item When the number of MFCC features is below 6000, which is a typical
                number of features generated by 60 seconds utterances (1ms frame shift),
                our method is slightly slower; but this is trivial since
                1 minute utterance is too small.
            \item When the number of MFCC features grows sufficiently large, our method
                shows great improvement. When training 512,000 features, our method
                is 5 times faster than comparing method.
        \end{itemize}
    \item With concurrency \\
        Our method shows considerable concurrency scalability that the running time
        is approximately lineary to the number of cores using.

        When using 8-cores, our method is \textbf{$19$ times} faster than comparing
        method.
\end{itemize}


\subsection{Change in MFCC Parameters}
The following tests reveal the effect of MFCC parameters on the final accuracy.
The tests were all performed with 40 speakers, each with 20 seconds for enrollment
and 5 seconds for recognition.
\begin{enumerate}
  \item Different Number of Cepstrums
    \begin{figure}[H]
      \centering
      \includegraphics[width=0.7\textwidth]{img/mfcc-nceps.pdf}
    \end{figure}


  \item Different Number of Filterbanks
    \begin{figure}[H]
      \centering
      \includegraphics[width=0.7\textwidth]{img/mfcc-nfilter.pdf}
    \end{figure}

  \item Different Size of Frame
    \begin{figure}[H]
      \centering
      \includegraphics[width=0.7\textwidth]{img/mfcc-frame-len.pdf}
    \end{figure}
\end{enumerate}

\subsection{Change in LPC Parameters}
\begin{enumerate}
  \item Different Number of Coefficient
    \begin{figure}[H]
      \centering
      \includegraphics[width=0.7\textwidth]{img/lpc-nceps.pdf}
    \end{figure}

  \item Different Size of Frame
    \begin{figure}[H]
      \centering
      \includegraphics[width=0.7\textwidth]{img/lpc-frame-len.pdf}
    \end{figure}
\end{enumerate}

\subsection{Change in GMM Components}

We examined our GMM compared to GMM from scikit-learn.
Test is conducted on 30-speaker corpus, 30 seconds training utterance
and 100 random sampled 5 seconds test utterance for each speaker.

As the following figure illustrates, when number of mixtures is small,
our GMM outperforms scikit-learn version by $10\%$, which indicates our
GMM models the distribution more accurately. The maximum accuracy
happens when the number of mixtures is around 32, reaching $0.965$. As
the number of mixtures increases, the decrease in accuracy
\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\textwidth]{img/nmixture.pdf}
\end{figure}

\subsection{hahhhaah??}

An apparent trade-off in speaker recognition task is the number of speakers
enrolled and the accuracy on recognization.
Also, the duration of signal for enrollment and test can have significant effect on the accuracy.
We've conducted test using well-tuned parameters for feature extraction as well as GMM, on dataset with
various number of people and with various test duration.

The configurations of this experiment is as followed:
\begin{itemize}
  \item MFCC: frame size is $32 ms $, 19 cepstrums, 55 filterbanks
  \item LPC: frame size is $32 ms $, 15 coefficients
  \item GMM from scikit-learn, number of mixtures is 32
  \item 20s utterance for enrollment
  \item 50 sampled test utterance for each user
\end{itemize}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\textwidth]{img/performance.pdf}
\end{figure}
