/* TODO : 重申一下项目概述 这个阶段的目标等 写一些开场的话 */

Algorithm
In this section, we present a prototype system processing the signals based on  Mel-frequency Cepstral Coefficients (MFCC),which is the most widely used spectral representation in Automatic Speech Recognition(ASR).

Input: 
We use the MOCHA-TIMIT corpus as the input dataset for training our system. 
(url : data.cstr.ed.ac.uk/ mocha/)
Corpus file name: fsew0.v1.1.tar.gz, maps0.tar.gz, msak0_v1.1.tar.gz
Languages: English
Sentences: A set of 460 sentences designed to include the main connected speech processes in English (e.g. assimilations, weak forms ..).
Subjects: 2 speakers, 1 male and 1 female are currently available but another 38 are planned to be completed by May 2001. The subjects have a variety of accents of English.
Conditions: All recordings made in the same sound damped studio at the Edinburgh Speech Production Facility. All data were recorded direct to computer and carefully synchronised.

3 samples are randomly chosen form the dataset as the input of the algorithm. Each sample contains 3 signals of the same sentence, but from different speakers.

Processing Procedure:
Each input speech signal is divided into successive overlapping frames. The frame size is 20ms while the length of time between each successive frames, the frame shift, is 10ms. We could fetch information about a small enough region in this way.
Those 20ms-length signals are windowed by Hamming Window in the frequency domain. /*TODO: 加上Hamming window的数学表达式*/
Then, We perform Discrete Fourier Transform (DFT) on windowed signals to compute their spectrums. For each of N discrete frequency bands we get a complex number X[k] representing magnitude and phase of that frequency component in the original signal. 
Considering the fact that human hearing is not equally sensitive to all frequency bands, and especially less sensitive at higher frequencies. Mel-scale is an efficient method to deal with this. 
/*TODO: Mel-scale 的定义式*/ 
A Mel is a unit of pitch. Mel-scale is approximately linear below 1 kHz and logarithmic above 1 kHz.  Applying the bank of filters according Mel-scale to the spectrum and the sum of its filtered spectral components are produced by each filter. /*TODO:这儿我不知道怎么样就变成13维向量了，求写一写*/  … and we get a vector.
For all feature vectors, we cluster them into a small number of classes.
Gaussian Mixture Model (GMM) can be used to calculate the probability that the class is generated by a given input modal.
The modal with maximum conditional probability is picked out as the result.

Performance:
/*TODO: 实验结果 昕昕写 */

Futue
A text-independent speaker-recognition system is presented at this period. 
In the future, we are focusing on variables in input limitation. The recognizability of speaker can be affected not only by the linguistic message but also the age, health, emotional state and effort level of the speaker. Background noise and performance of recording device also interfere
the classification process.
A goal we want to achieve in this project can be described as follows: For a clear conversation signal between two persons, with no sentences overlapped and significant interval between sentences, we may separate the conversation signal into two parts. Each part is exactly all the sentences spoken by a certain speaker.

/*TODO: YY一些可以实现这个目标的想法 Tim说不能乱讲容易被看出来 我先不写*/

